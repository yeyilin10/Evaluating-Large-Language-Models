# Evaluating Large Language Models

Welcome to the Evaluating Large Language Models repository! This project focuses on evaluating language models (LMs) on natural language inference (NLI) and bias detection within masked LMs.


## Introduction

Language models play a crucial role in various natural language processing tasks. This repository aims to provide a framework for evaluating the performance of large language models on two specific tasks: natural language inference (NLI) and bias detection within masked LMs.


## Usage

To evaluate language models on natural language inference (NLI), you can use the provided scripts. The repository includes the necessary code to preprocess the data and train and evaluate the models.

For bias detection within masked LMs, there are specific scripts. You can follow the instructions in the repository to run the evaluation and analyze the results.



